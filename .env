# .env
# Variáveis de Ambiente para a aplicação teacher_english

# --- Configurações do LLM ---
# URL base do servidor de inferência do LM Studio.
# Geralmente é localhost na porta 1234.
LLM_BASE_URL=http://localhost:1234/v1

# Chave de API para o LM Studio. Para uso local, qualquer string serve.
LLM_API_KEY=lm-studio_api_key_local

# Nome do modelo LLM carregado no LM Studio.
# AJUSTE ESTE VALOR para o nome EXATO do modelo que você carregou.
# Ex: gemma-2-2b-it, lmstudio-community/gemma-2-2b-it-GGUF, etc.
# Você pode encontrar este nome na aba 'Local Inference Server' do LM Studio.
LLM_MODEL_NAME=bartowski/llama-3.2-1b-instruct

# --- Configurações do MongoDB (para etapas futuras) ---
# URI de conexão com o MongoDB.
# Para um MongoDB local padrão, geralmente é assim:
# MONGO_URI=mongodb://localhost:27017/teacher_english_db

# Nome do banco de dados a ser usado no MongoDB.
# MONGO_DB_NAME=teacher_english_db

# Nome da coleção onde as provas e outros dados serão salvos.
# MONGO_COLLECTION_PROVAS=provas